{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4642226a51e34af69b3bf0ecef5b4af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2ddc2f8a81e44508ae2110bd1b381356",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9139cc8af26a485b91340ddb0a2f98a3",
              "IPY_MODEL_cb37ffbdb18440a1aed5623877ddc51f",
              "IPY_MODEL_579a807429404b71bcabe7891250495c"
            ]
          }
        },
        "2ddc2f8a81e44508ae2110bd1b381356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9139cc8af26a485b91340ddb0a2f98a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28169e2432c9427cb95f00ed1e200dc8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a59fdc181ab047c6acf5daf208669779"
          }
        },
        "cb37ffbdb18440a1aed5623877ddc51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2ac9304ed2b7454aa023b1efc3d16d0e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84068f5f6de049b08f5361d1eb1400ee"
          }
        },
        "579a807429404b71bcabe7891250495c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d59eb42c537946599c102ab2bd894322",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/? [00:05&lt;00:00,  1.84it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e71ded836a149579b6ed849682e1794"
          }
        },
        "28169e2432c9427cb95f00ed1e200dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a59fdc181ab047c6acf5daf208669779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ac9304ed2b7454aa023b1efc3d16d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84068f5f6de049b08f5361d1eb1400ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d59eb42c537946599c102ab2bd894322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e71ded836a149579b6ed849682e1794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik6KFYkEo23e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrzpekTCAXvX"
      },
      "source": [
        "from torchvision.datasets import CIFAR10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghJvJGD9q6Hk"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxwqQy0Hqt2j"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import glob\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from PIL import Image"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFH3oOMwsjLw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea6b895f-4197-436a-cc12-3c8861475859"
      },
      "source": [
        "lr = 0.001\n",
        "batch_size = 16\n",
        "beta1 = 0\n",
        "beta2 = 0.99\n",
        "criterion = nn.BCELoss()\n",
        "c_lambda = 10\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEf2xiKlqrMM"
      },
      "source": [
        "# class CelebA(Dataset):\n",
        "  \n",
        "#   def __init__(self, root, transform=None):\n",
        "#     self.files = glob.glob(os.path.join(root, \"*.jpg\"))\n",
        "#     self.transform = transform\n",
        "\n",
        "#   def __getitem__(self, index):\n",
        "\n",
        "#     image = Image.open(self.files[index]) \n",
        "\n",
        "#     if self.transform is not None:\n",
        "#       return self.transform(image)\n",
        "    \n",
        "#     return image\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_7j4kVq5q1"
      },
      "source": [
        "def loaderFunc(transform):\n",
        "  train_loader = DataLoader(\n",
        "    CIFAR10(root=\"/content\", download=True, train=True, transform=transform),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "  )\n",
        "\n",
        "  return train_loader"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-m8sSRosqnT"
      },
      "source": [
        "def sample_data(image_size=4):\n",
        "    \n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.CenterCrop(image_size),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])\n",
        "\n",
        "\n",
        "  loader = loaderFunc(transform)\n",
        "\n",
        "  for img, label in loader:\n",
        "      yield (img, label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNeFwJd7p-iM"
      },
      "source": [
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/06/Tables-Showing-Generator-and-Discriminator-Configuration-for-the-Progressive-Growing-GAN.png\"  width=\"1024\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHNR63_s1wha"
      },
      "source": [
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        # assuming input is in the from of (batch_size, channels, width, height)\n",
        "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True)\n",
        "                                  + 1e-8)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afJX5Mt3151W"
      },
      "source": [
        "from math import sqrt \n",
        "def EqualLR(module, input):\n",
        "\n",
        "  weight = getattr(module, 'weight')\n",
        "  del module._parameters['weight']\n",
        "  weight * sqrt(2 / (weight.size(1) * weight[0][0].numel()))\n",
        "  module.register_parameter(\"weight\", nn.Parameter(weight.data))\n",
        "  return input"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZnmcI-r18yZ"
      },
      "source": [
        "class EqualConv2d(nn.Module):\n",
        "  \n",
        "  def __init__(self, *args, **kwargs):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Conv2d(*args, **kwargs)\n",
        "    self.conv.register_forward_pre_hook(EqualLR)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRBQPRbOo6Zw"
      },
      "source": [
        "def GeneratorBlock(in_channel, out_channel, output_size, first_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if first_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=4, padding=3),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      nn.Upsample((output_size, output_size), mode='bilinear', align_corners=True),\n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "    )\n",
        "\n",
        "  return model  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJAXqq9RnRK"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block4_4 = GeneratorBlock(512, 512, 8, first_block=True)\n",
        "    self.block8_8 = GeneratorBlock(512, 512, 8)\n",
        "    self.block16_16 = GeneratorBlock(512, 512, 16)\n",
        "    self.block32_32 = GeneratorBlock(512, 512, 32)\n",
        "    self.block64_64 = GeneratorBlock(512, 256, 64)\n",
        "    self.block128_128 = GeneratorBlock(256, 128, 128)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "        self.block4_4,\n",
        "        self.block8_8,\n",
        "        self.block16_16,\n",
        "        self.block32_32,\n",
        "        self.block64_64,\n",
        "        self.block128_128\n",
        "    ])\n",
        "\n",
        "    self.to_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(256, 3, 1),\n",
        "      nn.Conv2d(128, 3, 1),\n",
        "    ])\n",
        "\n",
        "\n",
        "  def forward(self, x, step, alpha):\n",
        "    # we have six steps toward progressively increase the output\n",
        "    # alpha is the weight of output of new block compared to upsampled input\n",
        "    if step == 1: # no need to average\n",
        "      out = self.blocks[0](x)\n",
        "      out = self.to_rgbs[0](out)\n",
        "\n",
        "    elif step > 1:\n",
        "\n",
        "      for block in self.blocks[:step - 2]: # assuming all previous blocks have been trained completely\n",
        "        x = block(x)\n",
        "\n",
        "      x_small_block = self.blocks[step-2](x) # 512 * 32 * 32\n",
        "      x_small_image = self.to_rgbs[step-2](x_small_block) # 3 * 32 * 32\n",
        "\n",
        "      x_large_block = self.blocks[step-1](x_small_block) # 256 * 64 * 64\n",
        "      x_large_image = self.to_rgbs[step-1](x_large_block) # 3 * 64 * 64\n",
        "\n",
        "\n",
        "      x_small_upsample = F.interpolate(x_small_image, x_large_image.shape[-2:]) # 3 * 64 * 64\n",
        "\n",
        "      out = (alpha *  x_large_image) + (1 - alpha) * (x_small_upsample)\n",
        "\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDH-JnZYHPm"
      },
      "source": [
        "gen = Generator().to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn84hHtRY5fn",
        "outputId": "673c376b-0448-456b-a5e0-e32e382fd236"
      },
      "source": [
        "gen(torch.randn(16, 512, 1, 1).to(device), 4, 0.2).shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g3DKw5_z8Kz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW1j9BBz-WC1"
      },
      "source": [
        "def DiscriminatorBlock(in_channel, out_channel, output_size, last_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if last_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=4, padding=0),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      nn.Flatten(start_dim=1),\n",
        "      nn.Linear(512, 1),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.AvgPool2d(kernel_size=2),\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4KnipaT-GVK"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block64_64 = DiscriminatorBlock(128, 256, 64)\n",
        "    self.block32_32 = DiscriminatorBlock(256, 512, 32)\n",
        "    self.blcok16_16 = DiscriminatorBlock(512, 512, 16)\n",
        "    self.block8_8 = DiscriminatorBlock(512, 512, 8)\n",
        "    self.block4_4 = DiscriminatorBlock(512, 512, 4)\n",
        "    self.block1_1 = DiscriminatorBlock(512, 512, 1, last_block=True)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "      self.block64_64,\n",
        "      self.block32_32,\n",
        "      self.blcok16_16,\n",
        "      self.block8_8,\n",
        "      self.block4_4,\n",
        "      self.block1_1\n",
        "    ])\n",
        "\n",
        "    self.from_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(3, 128, 1),\n",
        "      nn.Conv2d(3, 256, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "    ])\n",
        "  \n",
        "\n",
        "  def forward(self, x_large, step, alpha):\n",
        "    \n",
        "    if step == 1:\n",
        "      out = self.from_rgbs[-step](x_large)\n",
        "      out = self.blocks[-step](out)\n",
        "    \n",
        "    elif step > 1:\n",
        "      \n",
        "      x_large_feature_map = self.from_rgbs[(6-step)](x_large) # input : 3 * 8 * 8 and output is 512 * 8 * 8\n",
        "      x_small = self.blocks[-step](x_large_feature_map) # last layer output is 512 * 4 * 4\n",
        "      \n",
        "      x_large_downsampled = F.avg_pool2d(self.from_rgbs[(6 - step) + 1](x_large), kernel_size=2) # input 3 * 8 * 8 => output is 512 * 8 * 8 => downsampled to 512 * 4 * 64\n",
        "\n",
        "      out = (1 - alpha) * x_large_downsampled + (alpha * x_small)\n",
        "\n",
        "      for block in self.blocks[(6 - step) + 1:]:\n",
        "        out = block(out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJTv8pBFwD0s"
      },
      "source": [
        "disc = Discriminator().to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9tReO2otNA"
      },
      "source": [
        "gen_optim = torch.optim.Adam(gen.parameters(), lr=lr , betas=(beta1, beta2))\n",
        "disc_optim = torch.optim.Adam(disc.parameters(), lr=lr , betas=(beta1, beta2))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY1lvWfrM2V4"
      },
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX1j3P4pSHsZ"
      },
      "source": [
        "def gradient_penalty(real, fake, epsilon, step, alpha):\n",
        "  \n",
        "  mixed_images = epsilon * real + (1 - epsilon) * fake\n",
        "  mixed_scores = disc(mixed_images, step, alpha)\n",
        "\n",
        "  gradients = torch.autograd.grad(\n",
        "      outputs=mixed_scores,\n",
        "      inputs=mixed_images,\n",
        "      grad_outputs=torch.ones_like(mixed_scores),\n",
        "      retain_graph=True,\n",
        "      create_graph=True,\n",
        "  )[0]\n",
        "\n",
        "  flat_gradients = gradients.reshape(len(gradients), -1)\n",
        "\n",
        "  norm = torch.norm(flat_gradients, dim=1)\n",
        "\n",
        "  gp = torch.mean((norm - 1) ** 2)\n",
        "\n",
        "  return gp"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771,
          "referenced_widgets": [
            "4642226a51e34af69b3bf0ecef5b4af6",
            "2ddc2f8a81e44508ae2110bd1b381356",
            "9139cc8af26a485b91340ddb0a2f98a3",
            "cb37ffbdb18440a1aed5623877ddc51f",
            "579a807429404b71bcabe7891250495c",
            "28169e2432c9427cb95f00ed1e200dc8",
            "a59fdc181ab047c6acf5daf208669779",
            "2ac9304ed2b7454aa023b1efc3d16d0e",
            "84068f5f6de049b08f5361d1eb1400ee",
            "d59eb42c537946599c102ab2bd894322",
            "6e71ded836a149579b6ed849682e1794"
          ]
        },
        "id": "keUlI2GTn7m-",
        "outputId": "3b92fa5e-edf5-4eb7-fc71-c63a08e96c1f"
      },
      "source": [
        "# step and alpha\n",
        "step = 1\n",
        "step_size = 0.001\n",
        "alpha = 0\n",
        "latent_space_size = 512\n",
        "\n",
        "for iteration, (real, _) in enumerate(tqdm(sample_data(2 ** (step + 1)))):\n",
        "\n",
        "  real = real.to(device)\n",
        "\n",
        "  alpha += step_size\n",
        "\n",
        "  if alpha == 1 and step < 4:\n",
        "    step += 1\n",
        "    alpha = 0\n",
        "\n",
        "  # Training Generator\n",
        "  gen_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(batch_size, latent_space_size, 1, 1).to(device), step, alpha)\n",
        "  pred_fake = disc(fake, step, alpha).reshape(-1)\n",
        "  gen_loss = - torch.mean(pred_fake)\n",
        "\n",
        "  gen_loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "  gen_optim.step()\n",
        "\n",
        "\n",
        "  # Training Discriminator\n",
        "  disc_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(batch_size, latent_space_size, 1, 1).to(device), step, alpha).detach()\n",
        "  pred_fake = disc(fake, step, alpha)\n",
        "\n",
        "  pred_real = disc(real, step, alpha)\n",
        "\n",
        "  epsilon = torch.randn(len(real), 1, 1, 1, requires_grad=True).to(device)\n",
        "  gp = gradient_penalty(real, fake, epsilon, step, alpha)\n",
        "\n",
        "  disc_loss = - torch.mean(pred_real - pred_fake) + (c_lambda * gp)\n",
        "\n",
        "  disc_loss.backward()\n",
        "\n",
        "  \n",
        "\n",
        "  disc_optim.step()\n",
        "\n",
        "  if iteration % 250 == 0:\n",
        "    visualize(fake, \"linear\")\n",
        "    visualize((torch.tanh(fake) + 1) / 2, \"tanh\")\n",
        "    visualize(real, \"Real\")\n",
        "\n",
        "    print(\"Gen Loss\", gen_loss.item())\n",
        "    print(\"Disc Loss\", disc_loss.item())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4642226a51e34af69b3bf0ecef5b4af6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gen Loss 64721052.0\n",
            "Disc Loss 2.325654559478776e+18\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-bd0be1250c04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mpred_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uylg-HkOKuSG"
      },
      "source": [
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuH5T3hpKqf1"
      },
      "source": [
        "def visualize(tensor, title):\n",
        "\n",
        "  detached_tensor = tensor.cpu().detach()\n",
        "  \n",
        "  image_grid = make_grid(detached_tensor, nrow=8)\n",
        "  \n",
        "  plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}