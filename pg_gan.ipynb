{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik6KFYkEo23e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8erye2lAiCTj",
        "outputId": "29be3fd4-644e-4ae2-d647-ec4929e1b6ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7M_4q3rbI-4"
      },
      "source": [
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "def visualize(tensor, title, path=\".\", save=False):\n",
        "\n",
        "  detached_tensor = tensor.cpu().detach()\n",
        "  \n",
        "  image_grid = make_grid(detached_tensor, nrow=8)\n",
        "  \n",
        "  plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "  plt.title(title)\n",
        "  \n",
        "  if save:\n",
        "    plt.savefig(os.path.join(path, title + \".png\"))\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghJvJGD9q6Hk"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf1_4Qucol8r"
      },
      "source": [
        "!mkdir \"/content/celebA\"\n",
        "!sudo unzip \"/content/drive/MyDrive/img_align_celeba.zip\" -d \"/content/celebA\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxwqQy0Hqt2j"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets import CIFAR10\n",
        "from PIL import Image\n",
        "from torch.utils.data import Subset"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFH3oOMwsjLw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aadb7eee-1a62-4a2d-b027-2cca20c413ce"
      },
      "source": [
        "lr = 0.001\n",
        "batch_size = 16\n",
        "beta1 = 0\n",
        "beta2 = 0.99\n",
        "criterion = nn.BCELoss()\n",
        "c_lambda = 10\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEf2xiKlqrMM"
      },
      "source": [
        "# class CelebA(Dataset):\n",
        "  \n",
        "#   def __init__(self, root, transform=None):\n",
        "#     self.files = glob.glob(os.path.join(root, \"*.jpg\"))\n",
        "#     self.transform = transform\n",
        "\n",
        "#   def __getitem__(self, index):\n",
        "\n",
        "#     image = Image.open(self.files[index]) \n",
        "\n",
        "#     if self.transform is not None:\n",
        "#       return self.transform(image)\n",
        "    \n",
        "#     return image\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_7j4kVq5q1"
      },
      "source": [
        "def loaderFunc(transform):\n",
        "  \n",
        "  # ds = CIFAR10('~/.torch/data/', train=True, download=True, transform=transform)\n",
        "  # dog_indices, deer_indices, other_indices = [], [], []\n",
        "  # dog_idx, deer_idx = ds.class_to_idx['dog'], ds.class_to_idx['airplane']\n",
        "\n",
        "  # for i in range(len(ds)):\n",
        "  #   current_class = ds[i][1]\n",
        "  #   if current_class == dog_idx:\n",
        "  #     dog_indices.append(i)\n",
        "  #   elif current_class == deer_idx:\n",
        "  #     deer_indices.append(i)\n",
        "  #   else:\n",
        "  #     other_indices.append(i)\n",
        "  # dog_indices = dog_indices[:int(0.6 * len(dog_indices))]\n",
        "  # deer_indices = deer_indices[:int(0.6 * len(deer_indices))]\n",
        "  # new_dataset = Subset(ds, deer_indices)\n",
        "  \n",
        "  # dataset = CelebA(\"/content/drive/MyDrive/haircolors/images/img_align_celeba/\", transform=transform)\n",
        "  # dataset = CIFAR10('~/.torch/data/', train=True, download=True, transform=transform)\n",
        "  dataset = ImageFolder(\"/content/celebA\", transform=transform)\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "  )\n",
        "\n",
        "  return train_loader"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-m8sSRosqnT"
      },
      "source": [
        "def sample_data(image_size=4):\n",
        "\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.CenterCrop(image_size),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])\n",
        "\n",
        "\n",
        "  loader = loaderFunc(transform)\n",
        "\n",
        "  for img, label in loader:\n",
        "      yield (img, label)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNeFwJd7p-iM"
      },
      "source": [
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/06/Tables-Showing-Generator-and-Discriminator-Configuration-for-the-Progressive-Growing-GAN.png\"  width=\"1024\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHNR63_s1wha"
      },
      "source": [
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        # assuming input is in the from of (batch_size, channels, width, height)\n",
        "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True)\n",
        "                                  + 1e-8)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afJX5Mt3151W"
      },
      "source": [
        "from math import sqrt \n",
        "def EqualLR(module, input):\n",
        "\n",
        "  weight = getattr(module, 'weight')\n",
        "  del module._parameters['weight']\n",
        "  weight = weight * sqrt(2 / (weight.size(1) * weight[0][0].numel()))\n",
        "  module.register_parameter(\"weight\", nn.Parameter(weight.data))\n",
        "  return input"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZnmcI-r18yZ"
      },
      "source": [
        "class EqualConv2d(nn.Module):\n",
        "  \n",
        "  def __init__(self, *args, **kwargs):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    conv = nn.Conv2d(*args, **kwargs)\n",
        "    conv.weight.data.normal_()\n",
        "    conv.bias.data.zero_()\n",
        "    conv.register_forward_pre_hook(EqualLR)\n",
        "    self.conv = conv\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRBQPRbOo6Zw"
      },
      "source": [
        "def GeneratorBlock(in_channel, out_channel, output_size, first_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if first_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=4, padding=3),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      nn.Upsample((output_size, output_size), mode='bilinear', align_corners=True),\n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "    )\n",
        "\n",
        "  return model  "
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJAXqq9RnRK"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block4_4 = GeneratorBlock(512, 512, 4, first_block=True)\n",
        "    self.block8_8 = GeneratorBlock(512, 512, 8)\n",
        "    self.block16_16 = GeneratorBlock(512, 512, 16)\n",
        "    self.block32_32 = GeneratorBlock(512, 512, 32)\n",
        "    self.block64_64 = GeneratorBlock(512, 256, 64)\n",
        "    self.block128_128 = GeneratorBlock(256, 128, 128)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "        self.block4_4,\n",
        "        self.block8_8,\n",
        "        self.block16_16,\n",
        "        self.block32_32,\n",
        "        self.block64_64,\n",
        "        self.block128_128\n",
        "    ])\n",
        "\n",
        "    self.to_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(256, 3, 1),\n",
        "      nn.Conv2d(128, 3, 1),\n",
        "    ])\n",
        "\n",
        "\n",
        "  def forward(self, x, step, alpha):\n",
        "    # we have six steps toward progressively increasing the output size\n",
        "    # alpha is the weight of output of new block compared to upsampled input\n",
        "    if step == 1: # no need to average\n",
        "      out = self.blocks[0](x)\n",
        "      out = self.to_rgbs[0](out)\n",
        "\n",
        "    elif step > 1:\n",
        "\n",
        "      for block in self.blocks[:step - 1]: # assuming all previous blocks have been trained completely\n",
        "        x = block(x)\n",
        "\n",
        "      # x_small_block = self.blocks[step-2](x) # 256 * 64 * 64\n",
        "      # x is 16 * 512 * 16 * 16\n",
        "      x_large_block = self.blocks[step-1](x) # 128 * 128 * 128\n",
        "      x_large_image = self.to_rgbs[step-1](x_large_block) # 3 * 128 * 128\n",
        "\n",
        "\n",
        "      x_small_upsample = F.interpolate(x, x_large_image.shape[-2:]) # 3 * 64 * 64\n",
        "      x_upsample_rgb = self.to_rgbs[step-2](x_small_upsample)\n",
        "\n",
        "      out = (alpha *  x_large_image) + (1 - alpha) * (x_upsample_rgb)\n",
        "\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDH-JnZYHPm"
      },
      "source": [
        "gen = Generator().to(device)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn84hHtRY5fn",
        "outputId": "3cd13b98-550c-4857-8ae9-039d19476935"
      },
      "source": [
        "gen(torch.randn(16, 512, 1, 1).to(device), 5, 0.2).shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g3DKw5_z8Kz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW1j9BBz-WC1"
      },
      "source": [
        "def DiscriminatorBlock(in_channel, out_channel, output_size, last_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if last_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=4, padding=0),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      nn.Flatten(start_dim=1),\n",
        "      nn.Linear(512, 1),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.AvgPool2d(kernel_size=2),\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4KnipaT-GVK"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block64_64 = DiscriminatorBlock(128, 256, 64)\n",
        "    self.block32_32 = DiscriminatorBlock(256, 512, 32)\n",
        "    self.blcok16_16 = DiscriminatorBlock(512, 512, 16)\n",
        "    self.block8_8 = DiscriminatorBlock(512, 512, 8)\n",
        "    self.block4_4 = DiscriminatorBlock(512, 512, 4)\n",
        "    self.block1_1 = DiscriminatorBlock(513, 512, 1, last_block=True)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "      self.block64_64,\n",
        "      self.block32_32,\n",
        "      self.blcok16_16,\n",
        "      self.block8_8,\n",
        "      self.block4_4,\n",
        "      self.block1_1\n",
        "    ])\n",
        "\n",
        "    self.from_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(3, 128, 1),\n",
        "      nn.Conv2d(3, 256, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "    ])\n",
        "  \n",
        "\n",
        "  def forward(self, x_large, step, alpha):\n",
        "      \n",
        "    # alpha\n",
        "    \n",
        "\n",
        "    if step == 1:\n",
        "      x_large = self.from_rgbs[(6-step)](x_large) # input : 3 * 8 * 8 and output is 512 * 8 * 8\n",
        "      minibatch_std = x_large.std(0).mean() # 1\n",
        "      minibatch_std = minibatch_std.expand(x_large.size(0), 1, 4, 4) # 16, 1, 4, 4\n",
        "      x_large = torch.cat([x_large, minibatch_std], dim=1)\n",
        "      out = self.blocks[-step](x_large) # last layer output is 512 * 4 * 4\n",
        "      return out\n",
        "\n",
        "    out = self.blocks[-step](self.from_rgbs[6 - step](x_large)) # last layer output is 512 * 4 * 4\n",
        "    \n",
        "    if step > 1:\n",
        "    \n",
        "      x_large_downsampled = self.from_rgbs[(6 - step) + 1](F.avg_pool2d(x_large, kernel_size=2)) # input 3 * 8 * 8 => 3 * 4 *4  and then from rgb to 512 * 4 *4 \n",
        "\n",
        "      out = (1 - alpha) * x_large_downsampled + (alpha * out)\n",
        "\n",
        "\n",
        "      # intermidiate lay\n",
        "      for block in self.blocks[(6 - step) + 1: -1]:\n",
        "        out = block(out)\n",
        "\n",
        "      # last layer needs mini-batch variation\n",
        "      minibatch_std = x_large.std(0).mean() # 1\n",
        "      minibatch_std = minibatch_std.expand(x_large.size(0), 1, 4, 4) # 16, 1, 4, 4\n",
        "      out = torch.cat([out, minibatch_std], dim=1)\n",
        "      out = self.blocks[5](out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJTv8pBFwD0s"
      },
      "source": [
        "disc = Discriminator().to(device)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWZCNeOVaxfU",
        "outputId": "6a676130-d281-4cbc-d910-61e645668193"
      },
      "source": [
        "disc(torch.randn(16, 3, 64, 64).to(device), 5, 0.2).shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9tReO2otNA"
      },
      "source": [
        "gen_optim = torch.optim.Adam(gen.parameters(), lr=lr , betas=(beta1, beta2))\n",
        "disc_optim = torch.optim.Adam(disc.parameters(), lr=lr , betas=(beta1, beta2))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY1lvWfrM2V4"
      },
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX1j3P4pSHsZ"
      },
      "source": [
        "def gradient_penalty(real, fake, epsilon, step, alpha):\n",
        "  \n",
        "  mixed_images = epsilon * real + (1 - epsilon) * fake\n",
        "  mixed_scores = disc(mixed_images, step, alpha)\n",
        "\n",
        "  gradients = torch.autograd.grad(\n",
        "      outputs=mixed_scores,\n",
        "      inputs=mixed_images,\n",
        "      grad_outputs=torch.ones_like(mixed_scores),\n",
        "      retain_graph=True,\n",
        "      create_graph=True,\n",
        "  )[0]\n",
        "\n",
        "  flat_gradients = gradients.reshape(len(gradients), -1)\n",
        "\n",
        "  norm = torch.norm(flat_gradients, dim=1)\n",
        "\n",
        "  gp = torch.mean((norm - 1) ** 2)\n",
        "\n",
        "  return gp"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J72ClzMoh-hT"
      },
      "source": [
        "# step and alpha\n",
        "step = 1\n",
        "step_size = 0.00002\n",
        "alpha = 0\n",
        "latent_space_size = 512\n",
        "i = 0\n",
        "stabilize = False"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPNvY34mibqZ"
      },
      "source": [
        "ckpt = torch.load(\"/content/drive/MyDrive/progressive_gan_checkpoints/cpt_step_4_epoch_20_iteration_2000\")\n",
        "disc.load_state_dict(ckpt[\"disc_model\"])\n",
        "gen.load_state_dict(ckpt[\"gen_model\"])\n",
        "disc_optim.load_state_dict(ckpt[\"disc_optim\"])\n",
        "gen_optim.load_state_dict(ckpt[\"gen_optim\"])\n",
        "epoch_t = ckpt[\"epoch\"]\n",
        "alpha = ckpt[\"alpha\"]\n",
        "step = ckpt[\"step\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdi1A2CGjab8"
      },
      "source": [
        "def accumulate(model1, model2, weight=0.999):\n",
        "  \n",
        "  model1_params = dict(model1.named_parameters())\n",
        "  model2_params = dict(model2.named_parameters())\n",
        "\n",
        "  for key in model1_params.keys():\n",
        "    model1_params[key].data.mul_(weight).data.add_((1 - weight) * model2_params[key].data)\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrhsMuKIjsrE"
      },
      "source": [
        "### Unit Test \n",
        "\n",
        "# gen1 = Generator()\n",
        "# gen2 = Generator()\n",
        "# accumulate(gen1, gen2, 0.5)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLMP6_vEl1XS"
      },
      "source": [
        "g_running = Generator()\n",
        "g_running.train(False)\n",
        "accumulate(g_running, gen, 0)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK7ZessInM-X"
      },
      "source": [
        "import numpy as np\n",
        "disc_loss_list = []\n",
        "gen_loss_list = []"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keUlI2GTn7m-"
      },
      "source": [
        "pbar = tqdm(range(0, 600000))\n",
        "dataset = sample_data(2 ** (step + 1))\n",
        "\n",
        "for iteration in pbar:\n",
        "\n",
        "  alpha = min(1, i * step_size)\n",
        "\n",
        "  if stabilize == False and i > 50000:\n",
        "    stabilize = True\n",
        "    alpha = 1\n",
        "    dataset = sample_data(2 ** (step + 1))\n",
        "  \n",
        "  if i > 100000:\n",
        "    alpha = 0\n",
        "    step += 1\n",
        "    stabilize = False\n",
        "    i = 0\n",
        "    \n",
        "    if step > 6:\n",
        "      step = 6\n",
        "      alpha = 0\n",
        "\n",
        "    dataset = sample_data(2 ** (step + 1))\n",
        "  i += 1\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  real, _ = next(dataset)\n",
        "\n",
        "  real = real.to(device)\n",
        "\n",
        "  # Training Discriminator\n",
        "  disc_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(len(real), latent_space_size, 1, 1).to(device), step, alpha).detach()\n",
        "  pred_fake = disc(fake, step, alpha)\n",
        "\n",
        "  pred_real = disc(real, step, alpha)\n",
        "\n",
        "  epsilon = torch.randn(len(real), 1, 1, 1, requires_grad=True).to(device)\n",
        "\n",
        "  gp = gradient_penalty(real, fake, epsilon, step, alpha)\n",
        "\n",
        "  disc_loss = - torch.mean(pred_real - pred_fake) + (c_lambda * gp)\n",
        "\n",
        "  disc_loss.backward()\n",
        "\n",
        "  disc_optim.step()\n",
        "\n",
        "  # Training Generator\n",
        "  gen_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(batch_size, latent_space_size, 1, 1).to(device), step, alpha)\n",
        "  pred_fake = disc(fake, step, alpha).reshape(-1)\n",
        "  gen_loss = - torch.mean(pred_fake)\n",
        "\n",
        "  gen_loss.backward()\n",
        "\n",
        "  gen_optim.step()\n",
        "\n",
        "  accumulate(g_running, gen)\n",
        "\n",
        "\n",
        "  disc_loss_list.append(disc_loss.item())\n",
        "  gen_loss_list.append(gen_loss.item())\n",
        "\n",
        "  pbar.set_description(\n",
        "    \"Generator loss : {:.5f}, Discriminator loss: {:.5f}, alpha is {:.5f} and step is {}\".format(gen_loss.item(), disc_loss.item(), alpha, step)\n",
        "  )\n",
        "\n",
        "  if iteration % 2500 == 0:\n",
        "    \n",
        "    fake_samples = g_running(\n",
        "        torch.randn(16, latent_space_size, 1, 1),\n",
        "        step, \n",
        "        alpha,\n",
        "    )\n",
        "    # visualize(fake_samples, \"linear_{}\".format(iteration))\n",
        "    visualize((torch.tanh(fake_samples) + 1) / 2, \"tanh_{}\".format(iteration), path=\"/content/samples\", save=True)\n",
        "    visualize(real, \"Real\")\n",
        "    \n",
        "  \n",
        "  if iteration % 5000 == 0:\n",
        "    torch.save({\n",
        "        \"gen_model\": gen.state_dict(),\n",
        "        \"gen_optim\": gen_optim.state_dict(),\n",
        "        \"disc_model\": disc.state_dict(),\n",
        "        \"disc_optim\": disc_optim.state_dict(),\n",
        "        \"iteration\": iteration,\n",
        "        \"step\": step,\n",
        "        \"alpha\": alpha,\n",
        "    }, \"/content/drive/MyDrive/progressive_gan_checkpoints/cpt_step_{}_epoch_{}_iteration_{}\".format(step, epoch, iteration))\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUQAJO0-ugJD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}