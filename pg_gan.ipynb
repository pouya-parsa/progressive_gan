{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik6KFYkEo23e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghJvJGD9q6Hk"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxwqQy0Hqt2j"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import glob\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFH3oOMwsjLw"
      },
      "source": [
        "lr = 0.001\n",
        "batch_size = 16\n",
        "beta1 = 0\n",
        "beta2 = 0.99\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEf2xiKlqrMM"
      },
      "source": [
        "class CelebA(Dataset):\n",
        "  \n",
        "  def __init__(self, root, transform=None):\n",
        "    self.files = glob.glob(os.path.join(root, \"*.jpg\"))\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    image = Image.open(self.files[index]) \n",
        "\n",
        "    if self.transform is not None:\n",
        "      return self.transform(image)\n",
        "    \n",
        "    return image\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_7j4kVq5q1"
      },
      "source": [
        "def loaderFunc(transform):\n",
        "  train_loader = DataLoader(\n",
        "    CelebA(\"/content/drive/MyDrive/haircolors/images/img_align_celeba/\", transform=transform),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "  )\n",
        "\n",
        "  return train_loader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-m8sSRosqnT"
      },
      "source": [
        "def sample_data(image_size=4):\n",
        "    \n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.CenterCrop(image_size),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])\n",
        "\n",
        "\n",
        "  loader = loaderFunc(transform)\n",
        "\n",
        "  for img in loader:\n",
        "      yield img"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNeFwJd7p-iM"
      },
      "source": [
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/06/Tables-Showing-Generator-and-Discriminator-Configuration-for-the-Progressive-Growing-GAN.png\"  width=\"1024\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRBQPRbOo6Zw"
      },
      "source": [
        "def GeneratorBlock(in_channel, out_channel, output_size, first_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if first_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=4, padding=3),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      nn.Upsample((output_size, output_size), mode='bilinear', align_corners=True),\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "  return model  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJAXqq9RnRK"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block4_4 = GeneratorBlock(512, 512, 8, first_block=True)\n",
        "    self.block8_8 = GeneratorBlock(512, 512, 8)\n",
        "    self.block16_16 = GeneratorBlock(512, 512, 16)\n",
        "    self.block32_32 = GeneratorBlock(512, 512, 32)\n",
        "    self.block64_64 = GeneratorBlock(512, 256, 64)\n",
        "    self.block128_128 = GeneratorBlock(256, 128, 128)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "        self.block4_4,\n",
        "        self.block8_8,\n",
        "        self.block16_16,\n",
        "        self.block32_32,\n",
        "        self.block64_64,\n",
        "        self.block128_128\n",
        "    ])\n",
        "\n",
        "    self.to_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(256, 3, 1),\n",
        "      nn.Conv2d(128, 3, 1),\n",
        "    ])\n",
        "\n",
        "\n",
        "  def forward(self, x, step, alpha):\n",
        "    # we have six steps toward progressively increase the output\n",
        "    # alpha is the weight of output of new block compared to upsampled input\n",
        "    if step == 1: # no need to average\n",
        "      out = self.blocks[0](x)\n",
        "\n",
        "    elif step > 1:\n",
        "\n",
        "      for block in self.blocks[:step - 2]: # assuming all previous blocks have been trained completely\n",
        "        x = block(x)\n",
        "\n",
        "      x_small_block = self.blocks[step-2](x) # 512 * 32 * 32\n",
        "      x_small_image = self.to_rgbs[step-2](x_small_block) # 3 * 32 * 32\n",
        "\n",
        "      x_large_block = self.blocks[step-1](x_small_block) # 256 * 64 * 64\n",
        "      x_large_image = self.to_rgbs[step-1](x_large_block) # 3 * 64 * 64\n",
        "\n",
        "\n",
        "      x_small_upsample = F.interpolate(x_small_image, x_large_image.shape[-2:]) # 3 * 64 * 64\n",
        "\n",
        "      out = (alpha *  x_large_image) + (1 - alpha) * (x_small_upsample)\n",
        "\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDH-JnZYHPm"
      },
      "source": [
        "gen = Generator()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn84hHtRY5fn",
        "outputId": "741c0891-9bf9-430d-9922-8e7965cc9354"
      },
      "source": [
        "gen(torch.randn(16, 512, 1, 1), 6, 0.2).shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 128, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g3DKw5_z8Kz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zadeIb0o2A1g"
      },
      "source": [
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True)\n",
        "                                  + 1e-8)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z8tRPwH2SI1",
        "outputId": "97babbbc-ac80-4ffb-f804-180e44def181"
      },
      "source": [
        "px = PixelNorm()\n",
        "px(torch.randn(16, 512))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.5158,  0.6708,  0.8473,  ...,  0.4025, -0.3423,  1.4040],\n",
              "        [-0.0140, -0.9758, -1.4042,  ..., -0.5419,  1.6229,  0.8273],\n",
              "        [-0.3933, -0.6400,  0.5148,  ...,  0.8503,  0.5920,  0.0959],\n",
              "        ...,\n",
              "        [ 0.2634,  0.3666, -1.0588,  ..., -2.2999, -1.0695, -0.8408],\n",
              "        [ 0.2018, -0.3985,  0.2101,  ..., -0.8172, -0.1167, -1.4461],\n",
              "        [-1.1806, -1.9183, -0.2650,  ..., -0.7813,  0.5524, -0.2943]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW1j9BBz-WC1"
      },
      "source": [
        "def DiscriminatorBlock(in_channel, out_channel, output_size, last_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if last_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=4, padding=0),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      nn.Flatten(start_dim=1),\n",
        "      nn.Linear(512, 1),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.AvgPool2d(kernel_size=2),\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4KnipaT-GVK"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block64_64 = DiscriminatorBlock(128, 256, 64)\n",
        "    self.block32_32 = DiscriminatorBlock(256, 512, 32)\n",
        "    self.blcok16_16 = DiscriminatorBlock(512, 512, 16)\n",
        "    self.block8_8 = DiscriminatorBlock(512, 512, 8)\n",
        "    self.block4_4 = DiscriminatorBlock(512, 512, 4)\n",
        "    self.block1_1 = DiscriminatorBlock(512, 512, 1, last_block=True)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "      self.block64_64,\n",
        "      self.block32_32,\n",
        "      self.blcok16_16,\n",
        "      self.block8_8,\n",
        "      self.block4_4,\n",
        "      self.block1_1\n",
        "    ])\n",
        "\n",
        "    self.from_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(3, 128, 1),\n",
        "      nn.Conv2d(3, 256, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "    ])\n",
        "  \n",
        "\n",
        "  def forward(self, x_large, step, alpha):\n",
        "    \n",
        "    if step == 1:\n",
        "      print(self.blocks[-step])\n",
        "      out = self.blocks[-step](x_large)\n",
        "    \n",
        "    elif step > 1:\n",
        "      \n",
        "      x_large_feature_map = self.from_rgbs[(6-step)](x_large) # input : 3 * 8 * 8 and output is 512 * 8 * 8\n",
        "      x_small = self.blocks[-step](x_large_feature_map) # last layer output is 512 * 4 * 4\n",
        "      \n",
        "      x_large_downsampled = F.avg_pool2d(self.from_rgbs[(6 - step) + 1](x_large), kernel_size=2) # input 3 * 8 * 8 => output is 512 * 8 * 8 => downsampled to 512 * 4 * 64\n",
        "\n",
        "      out = (1 - alpha) * x_large_downsampled + (alpha * x_small)\n",
        "\n",
        "      for block in self.blocks[(6 - step) + 1:]:\n",
        "        out = block(out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJTv8pBFwD0s"
      },
      "source": [
        "disc = Discriminator()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9tReO2otNA"
      },
      "source": [
        "gen_optim = torch.optim.Adam(gen.parameters(), lr=lr , betas=(beta1, beta2))\n",
        "disc_optim = torch.optim.Adam(disc.parameters(), lr=lr , betas=(beta1, beta2))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "keUlI2GTn7m-",
        "outputId": "7b0b1232-6c71-42ef-99d9-3b8587a66caf"
      },
      "source": [
        "# step and alpha\n",
        "step = 1\n",
        "step_size = 0.001\n",
        "alpha = 0\n",
        "latent_space_size = 512\n",
        "\n",
        "for real in sample_data(2 ** (step + 1)):\n",
        "\n",
        "  alpha += step_size\n",
        "\n",
        "  if alpha == 1 and step < 6:\n",
        "    step += 1\n",
        "    alpha = 0\n",
        "\n",
        "  # Training Generator\n",
        "  gen_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(batch_size, latent_space_size, 1, 1), step, alpha)\n",
        "  pred_fake = disc(fake, step, alpha).reshape(-1)\n",
        "  gen_loss = criterion(pred_fake, torch.ones_like(pred_fake).float())\n",
        "\n",
        "  gen_loss.backward()\n",
        "\n",
        "  gen_optim.step()\n",
        "\n",
        "\n",
        "  # Training Discriminator\n",
        "  disc_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(batch_size, latent_space_size, 1, 1), step, alpha).detach()\n",
        "  pred_fake = disc(fake, step, alpha)\n",
        "\n",
        "  pred_real = disc(real, step, alpha)\n",
        "\n",
        "  disc_loss = (1/2) * (criterion(pred_fake, torch.zeros(pred_fake)) + criterion(pred_real, torch.ones(pred_real)))\n",
        "\n",
        "  disc_loss.backward()\n",
        "\n",
        "  disc_optim.step()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): LeakyReLU(negative_slope=0.2)\n",
            "  (2): Conv2d(512, 512, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (3): LeakyReLU(negative_slope=0.2)\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-66f8ab07d507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_space_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mpred_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mgen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2891\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh2odYY4wQcx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}