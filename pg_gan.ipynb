{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df5e05edac3c4cb5bb0aae59f87a59b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_649b0424f1c7444ea354b63f9cc7e1bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff08ac879b0844ca9872e146a0609089",
              "IPY_MODEL_4af91d7f10f941d6b08de4ced24a100e",
              "IPY_MODEL_e643481d9c4d4654b894fffe6acac1e2"
            ]
          }
        },
        "649b0424f1c7444ea354b63f9cc7e1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff08ac879b0844ca9872e146a0609089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08458948321847619dd76437dfd36d63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Generator loss : -2.05397, Discriminator loss: -0.77043, alpha is 0.002 and step is 1:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ad2e55028334bb3a7c5c6e077ee01b9"
          }
        },
        "4af91d7f10f941d6b08de4ced24a100e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0bd4e54b20e4dadb1492612604d3320",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 600000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67cb9fd508a044ccaa383aa048554cfe"
          }
        },
        "e643481d9c4d4654b894fffe6acac1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1b88839978c41f1a50c0a2477248641",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29/600000 [01:29&lt;464:04:25,  2.78s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83baa36d8dab4cfaa0a35750b964a613"
          }
        },
        "08458948321847619dd76437dfd36d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ad2e55028334bb3a7c5c6e077ee01b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0bd4e54b20e4dadb1492612604d3320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67cb9fd508a044ccaa383aa048554cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1b88839978c41f1a50c0a2477248641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83baa36d8dab4cfaa0a35750b964a613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik6KFYkEo23e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8erye2lAiCTj",
        "outputId": "29be3fd4-644e-4ae2-d647-ec4929e1b6ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7M_4q3rbI-4"
      },
      "source": [
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "def visualize(tensor, title, path=\".\", save=False):\n",
        "\n",
        "  detached_tensor = tensor.cpu().detach()\n",
        "  \n",
        "  image_grid = make_grid(detached_tensor, nrow=8)\n",
        "  \n",
        "  plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "  plt.title(title)\n",
        "  \n",
        "  if save:\n",
        "    plt.savefig(os.path.join(path, title + \".png\"))\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghJvJGD9q6Hk"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf1_4Qucol8r"
      },
      "source": [
        "!mkdir \"/content/celebA\"\n",
        "!sudo unzip \"/content/drive/MyDrive/img_align_celeba.zip\" -d \"/content/celebA\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxwqQy0Hqt2j"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets import CIFAR10\n",
        "from PIL import Image\n",
        "from torch.utils.data import Subset"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFH3oOMwsjLw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aadb7eee-1a62-4a2d-b027-2cca20c413ce"
      },
      "source": [
        "lr = 0.001\n",
        "batch_size = 16\n",
        "beta1 = 0\n",
        "beta2 = 0.99\n",
        "criterion = nn.BCELoss()\n",
        "c_lambda = 10\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEf2xiKlqrMM"
      },
      "source": [
        "# class CelebA(Dataset):\n",
        "  \n",
        "#   def __init__(self, root, transform=None):\n",
        "#     self.files = glob.glob(os.path.join(root, \"*.jpg\"))\n",
        "#     self.transform = transform\n",
        "\n",
        "#   def __getitem__(self, index):\n",
        "\n",
        "#     image = Image.open(self.files[index]) \n",
        "\n",
        "#     if self.transform is not None:\n",
        "#       return self.transform(image)\n",
        "    \n",
        "#     return image\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_7j4kVq5q1"
      },
      "source": [
        "def loaderFunc(transform):\n",
        "  \n",
        "  # ds = CIFAR10('~/.torch/data/', train=True, download=True, transform=transform)\n",
        "  # dog_indices, deer_indices, other_indices = [], [], []\n",
        "  # dog_idx, deer_idx = ds.class_to_idx['dog'], ds.class_to_idx['airplane']\n",
        "\n",
        "  # for i in range(len(ds)):\n",
        "  #   current_class = ds[i][1]\n",
        "  #   if current_class == dog_idx:\n",
        "  #     dog_indices.append(i)\n",
        "  #   elif current_class == deer_idx:\n",
        "  #     deer_indices.append(i)\n",
        "  #   else:\n",
        "  #     other_indices.append(i)\n",
        "  # dog_indices = dog_indices[:int(0.6 * len(dog_indices))]\n",
        "  # deer_indices = deer_indices[:int(0.6 * len(deer_indices))]\n",
        "  # new_dataset = Subset(ds, deer_indices)\n",
        "  \n",
        "  # dataset = CelebA(\"/content/drive/MyDrive/haircolors/images/img_align_celeba/\", transform=transform)\n",
        "  # dataset = CIFAR10('~/.torch/data/', train=True, download=True, transform=transform)\n",
        "  dataset = ImageFolder(\"/content/celebA\", transform=transform)\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "  )\n",
        "\n",
        "  return train_loader"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-m8sSRosqnT"
      },
      "source": [
        "def sample_data(image_size=4):\n",
        "\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.CenterCrop(image_size),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])\n",
        "\n",
        "\n",
        "  loader = loaderFunc(transform)\n",
        "\n",
        "  for img, label in loader:\n",
        "      yield (img, label)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNeFwJd7p-iM"
      },
      "source": [
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/06/Tables-Showing-Generator-and-Discriminator-Configuration-for-the-Progressive-Growing-GAN.png\"  width=\"1024\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHNR63_s1wha"
      },
      "source": [
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        # assuming input is in the from of (batch_size, channels, width, height)\n",
        "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True)\n",
        "                                  + 1e-8)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afJX5Mt3151W"
      },
      "source": [
        "from math import sqrt \n",
        "def EqualLR(module, input):\n",
        "\n",
        "  weight = getattr(module, 'weight')\n",
        "  del module._parameters['weight']\n",
        "  weight = weight * sqrt(2 / (weight.size(1) * weight[0][0].numel()))\n",
        "  module.register_parameter(\"weight\", nn.Parameter(weight.data))\n",
        "  return input"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZnmcI-r18yZ"
      },
      "source": [
        "class EqualConv2d(nn.Module):\n",
        "  \n",
        "  def __init__(self, *args, **kwargs):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    conv = nn.Conv2d(*args, **kwargs)\n",
        "    conv.weight.data.normal_()\n",
        "    conv.bias.data.zero_()\n",
        "    conv.register_forward_pre_hook(EqualLR)\n",
        "    self.conv = conv\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRBQPRbOo6Zw"
      },
      "source": [
        "def GeneratorBlock(in_channel, out_channel, output_size, first_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if first_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=4, padding=3),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      nn.Upsample((output_size, output_size), mode='bilinear', align_corners=True),\n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "    )\n",
        "\n",
        "  return model  "
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJAXqq9RnRK"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block4_4 = GeneratorBlock(512, 512, 4, first_block=True)\n",
        "    self.block8_8 = GeneratorBlock(512, 512, 8)\n",
        "    self.block16_16 = GeneratorBlock(512, 512, 16)\n",
        "    self.block32_32 = GeneratorBlock(512, 512, 32)\n",
        "    self.block64_64 = GeneratorBlock(512, 256, 64)\n",
        "    self.block128_128 = GeneratorBlock(256, 128, 128)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "        self.block4_4,\n",
        "        self.block8_8,\n",
        "        self.block16_16,\n",
        "        self.block32_32,\n",
        "        self.block64_64,\n",
        "        self.block128_128\n",
        "    ])\n",
        "\n",
        "    self.to_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(256, 3, 1),\n",
        "      nn.Conv2d(128, 3, 1),\n",
        "    ])\n",
        "\n",
        "\n",
        "  def forward(self, x, step, alpha):\n",
        "    # we have six steps toward progressively increasing the output size\n",
        "    # alpha is the weight of output of new block compared to upsampled input\n",
        "    if step == 1: # no need to average\n",
        "      out = self.blocks[0](x)\n",
        "      out = self.to_rgbs[0](out)\n",
        "\n",
        "    elif step > 1:\n",
        "\n",
        "      for block in self.blocks[:step - 1]: # assuming all previous blocks have been trained completely\n",
        "        x = block(x)\n",
        "\n",
        "      # x_small_block = self.blocks[step-2](x) # 256 * 64 * 64\n",
        "      # x is 16 * 512 * 16 * 16\n",
        "      x_large_block = self.blocks[step-1](x) # 128 * 128 * 128\n",
        "      x_large_image = self.to_rgbs[step-1](x_large_block) # 3 * 128 * 128\n",
        "\n",
        "\n",
        "      x_small_upsample = F.interpolate(x, x_large_image.shape[-2:]) # 3 * 64 * 64\n",
        "      x_upsample_rgb = self.to_rgbs[step-2](x_small_upsample)\n",
        "\n",
        "      out = (alpha *  x_large_image) + (1 - alpha) * (x_upsample_rgb)\n",
        "\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDH-JnZYHPm"
      },
      "source": [
        "gen = Generator().to(device)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn84hHtRY5fn",
        "outputId": "3cd13b98-550c-4857-8ae9-039d19476935"
      },
      "source": [
        "gen(torch.randn(16, 512, 1, 1).to(device), 5, 0.2).shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g3DKw5_z8Kz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW1j9BBz-WC1"
      },
      "source": [
        "def DiscriminatorBlock(in_channel, out_channel, output_size, last_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if last_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=4, padding=0),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      nn.Flatten(start_dim=1),\n",
        "      nn.Linear(512, 1),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.AvgPool2d(kernel_size=2),\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4KnipaT-GVK"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block64_64 = DiscriminatorBlock(128, 256, 64)\n",
        "    self.block32_32 = DiscriminatorBlock(256, 512, 32)\n",
        "    self.blcok16_16 = DiscriminatorBlock(512, 512, 16)\n",
        "    self.block8_8 = DiscriminatorBlock(512, 512, 8)\n",
        "    self.block4_4 = DiscriminatorBlock(512, 512, 4)\n",
        "    self.block1_1 = DiscriminatorBlock(513, 512, 1, last_block=True)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "      self.block64_64,\n",
        "      self.block32_32,\n",
        "      self.blcok16_16,\n",
        "      self.block8_8,\n",
        "      self.block4_4,\n",
        "      self.block1_1\n",
        "    ])\n",
        "\n",
        "    self.from_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(3, 128, 1),\n",
        "      nn.Conv2d(3, 256, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "    ])\n",
        "  \n",
        "\n",
        "  def forward(self, x_large, step, alpha):\n",
        "      \n",
        "    # alpha\n",
        "    \n",
        "\n",
        "    if step == 1:\n",
        "      x_large = self.from_rgbs[(6-step)](x_large) # input : 3 * 8 * 8 and output is 512 * 8 * 8\n",
        "      minibatch_std = x_large.std(0).mean() # 1\n",
        "      minibatch_std = minibatch_std.expand(x_large.size(0), 1, 4, 4) # 16, 1, 4, 4\n",
        "      x_large = torch.cat([x_large, minibatch_std], dim=1)\n",
        "      out = self.blocks[-step](x_large) # last layer output is 512 * 4 * 4\n",
        "      return out\n",
        "\n",
        "    out = self.blocks[-step](self.from_rgbs[6 - step](x_large)) # last layer output is 512 * 4 * 4\n",
        "    \n",
        "    if step > 1:\n",
        "    \n",
        "      x_large_downsampled = self.from_rgbs[(6 - step) + 1](F.avg_pool2d(x_large, kernel_size=2)) # input 3 * 8 * 8 => 3 * 4 *4  and then from rgb to 512 * 4 *4 \n",
        "\n",
        "      out = (1 - alpha) * x_large_downsampled + (alpha * out)\n",
        "\n",
        "\n",
        "      # intermidiate lay\n",
        "      for block in self.blocks[(6 - step) + 1: -1]:\n",
        "        out = block(out)\n",
        "\n",
        "      # last layer needs mini-batch variation\n",
        "      minibatch_std = x_large.std(0).mean() # 1\n",
        "      minibatch_std = minibatch_std.expand(x_large.size(0), 1, 4, 4) # 16, 1, 4, 4\n",
        "      out = torch.cat([out, minibatch_std], dim=1)\n",
        "      out = self.blocks[5](out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJTv8pBFwD0s"
      },
      "source": [
        "disc = Discriminator().to(device)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWZCNeOVaxfU",
        "outputId": "6a676130-d281-4cbc-d910-61e645668193"
      },
      "source": [
        "disc(torch.randn(16, 3, 64, 64).to(device), 5, 0.2).shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9tReO2otNA"
      },
      "source": [
        "gen_optim = torch.optim.Adam(gen.parameters(), lr=lr , betas=(beta1, beta2))\n",
        "disc_optim = torch.optim.Adam(disc.parameters(), lr=lr , betas=(beta1, beta2))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY1lvWfrM2V4"
      },
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX1j3P4pSHsZ"
      },
      "source": [
        "def gradient_penalty(real, fake, epsilon, step, alpha):\n",
        "  \n",
        "  mixed_images = epsilon * real + (1 - epsilon) * fake\n",
        "  mixed_scores = disc(mixed_images, step, alpha)\n",
        "\n",
        "  gradients = torch.autograd.grad(\n",
        "      outputs=mixed_scores,\n",
        "      inputs=mixed_images,\n",
        "      grad_outputs=torch.ones_like(mixed_scores),\n",
        "      retain_graph=True,\n",
        "      create_graph=True,\n",
        "  )[0]\n",
        "\n",
        "  flat_gradients = gradients.reshape(len(gradients), -1)\n",
        "\n",
        "  norm = torch.norm(flat_gradients, dim=1)\n",
        "\n",
        "  gp = torch.mean((norm - 1) ** 2)\n",
        "\n",
        "  return gp"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J72ClzMoh-hT"
      },
      "source": [
        "# step and alpha\n",
        "step = 1\n",
        "step_size = 0.00002\n",
        "alpha = 0\n",
        "latent_space_size = 512\n",
        "epoch_t = 0"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPNvY34mibqZ"
      },
      "source": [
        "ckpt = torch.load(\"/content/drive/MyDrive/progressive_gan_checkpoints/cpt_step_4_epoch_20_iteration_2000\")\n",
        "disc.load_state_dict(ckpt[\"disc_model\"])\n",
        "gen.load_state_dict(ckpt[\"gen_model\"])\n",
        "disc_optim.load_state_dict(ckpt[\"disc_optim\"])\n",
        "gen_optim.load_state_dict(ckpt[\"gen_optim\"])\n",
        "epoch_t = ckpt[\"epoch\"]\n",
        "alpha = ckpt[\"alpha\"]\n",
        "step = ckpt[\"step\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdi1A2CGjab8"
      },
      "source": [
        "def accumulate(model1, model2, weight=0.999):\n",
        "  \n",
        "  model1_params = dict(model1.named_parameters())\n",
        "  model2_params = dict(model2.named_parameters())\n",
        "\n",
        "  for key in model1_params.keys():\n",
        "    model1_params[key].data.mul_(weight).data.add_((1 - weight) * model2_params[key].data)\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrhsMuKIjsrE"
      },
      "source": [
        "### Unit Test \n",
        "\n",
        "# gen1 = Generator()\n",
        "# gen2 = Generator()\n",
        "# accumulate(gen1, gen2, 0.5)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLMP6_vEl1XS"
      },
      "source": [
        "g_running = Generator()\n",
        "g_running.train(False)\n",
        "accumulate(g_running, gen, 0)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK7ZessInM-X"
      },
      "source": [
        "import numpy as np\n",
        "disc_loss_list = []\n",
        "gen_loss_list = []"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705,
          "referenced_widgets": [
            "df5e05edac3c4cb5bb0aae59f87a59b0",
            "649b0424f1c7444ea354b63f9cc7e1bf",
            "ff08ac879b0844ca9872e146a0609089",
            "4af91d7f10f941d6b08de4ced24a100e",
            "e643481d9c4d4654b894fffe6acac1e2",
            "08458948321847619dd76437dfd36d63",
            "8ad2e55028334bb3a7c5c6e077ee01b9",
            "b0bd4e54b20e4dadb1492612604d3320",
            "67cb9fd508a044ccaa383aa048554cfe",
            "c1b88839978c41f1a50c0a2477248641",
            "83baa36d8dab4cfaa0a35750b964a613"
          ]
        },
        "id": "keUlI2GTn7m-",
        "outputId": "2eca1bc7-2228-4941-c3eb-e8497b901260"
      },
      "source": [
        "pbar = tqdm(range(0, 600000))\n",
        "  \n",
        "for iteration in pbar:\n",
        "\n",
        "  if step <= 4 and alpha < 1:\n",
        "    alpha += step_size\n",
        "\n",
        "  if alpha > 1 and step < 4:\n",
        "    step += 1\n",
        "    alpha = 0\n",
        "\n",
        "  dataset = sample_data(2 ** (step + 1))\n",
        "  \n",
        "  real, _ = next(dataset)\n",
        "\n",
        "  real = real.to(device)\n",
        "\n",
        "  # Training Discriminator\n",
        "  disc_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(len(real), latent_space_size, 1, 1).to(device), step, alpha).detach()\n",
        "  pred_fake = disc(fake, step, alpha)\n",
        "\n",
        "  pred_real = disc(real, step, alpha)\n",
        "\n",
        "  epsilon = torch.randn(len(real), 1, 1, 1, requires_grad=True).to(device)\n",
        "\n",
        "  gp = gradient_penalty(real, fake, epsilon, step, alpha)\n",
        "\n",
        "  disc_loss = - torch.mean(pred_real - pred_fake) + (c_lambda * gp)\n",
        "\n",
        "  disc_loss.backward()\n",
        "\n",
        "  disc_optim.step()\n",
        "\n",
        "  # Training Generator\n",
        "  gen_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(batch_size, latent_space_size, 1, 1).to(device), step, alpha)\n",
        "  pred_fake = disc(fake, step, alpha).reshape(-1)\n",
        "  gen_loss = - torch.mean(pred_fake)\n",
        "\n",
        "  gen_loss.backward()\n",
        "\n",
        "  gen_optim.step()\n",
        "\n",
        "  accumulate(g_running, gen)\n",
        "\n",
        "\n",
        "  disc_loss_list.append(disc_loss.item())\n",
        "  gen_loss_list.append(gen_loss.item())\n",
        "\n",
        "  pbar.set_description(\n",
        "    \"Generator loss : {:.5f}, Discriminator loss: {:.5f}, alpha is {:.5f} and step is {}\".format(gen_loss.item(), disc_loss.item(), alpha, step)\n",
        "  )\n",
        "\n",
        "  if iteration % 2500 == 0:\n",
        "    \n",
        "    fake_samples = g_running(\n",
        "        torch.randn(16, latent_space_size, 1, 1),\n",
        "        step, \n",
        "        alpha,\n",
        "    )\n",
        "    # visualize(fake_samples, \"linear_{}\".format(iteration))\n",
        "    visualize((torch.tanh(fake_samples) + 1) / 2, \"tanh_{}\".format(iteration), path=\"/content/samples\", save=True)\n",
        "    visualize(real, \"Real\")\n",
        "    \n",
        "  \n",
        "  if iteration % 5000 == 0:\n",
        "    torch.save({\n",
        "        \"gen_model\": gen.state_dict(),\n",
        "        \"gen_optim\": gen_optim.state_dict(),\n",
        "        \"disc_model\": disc.state_dict(),\n",
        "        \"disc_optim\": disc_optim.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"iteration\": iteration,\n",
        "        \"step\": step,\n",
        "        \"alpha\": alpha,\n",
        "    }, \"/content/drive/MyDrive/progressive_gan_checkpoints/cpt_step_{}_epoch_{}_iteration_{}\".format(step, epoch, iteration))\n",
        "\n",
        "    "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df5e05edac3c4cb5bb0aae59f87a59b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/600000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-339fd8f64fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0mgen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mgen_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUQAJO0-ugJD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}