{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik6KFYkEo23e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import os\n",
        "from math import sqrt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8erye2lAiCTj",
        "outputId": "28ad9a90-ca6e-4643-850c-9b453de264e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7M_4q3rbI-4"
      },
      "source": [
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "def visualize(tensor, title, path=\".\", save=False):\n",
        "\n",
        "  detached_tensor = tensor.cpu().detach()\n",
        "  \n",
        "  image_grid = make_grid(detached_tensor, nrow=8)\n",
        "  \n",
        "  plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "  plt.title(title)\n",
        "  \n",
        "  if save:\n",
        "    plt.savefig(os.path.join(path, title + \".png\"))\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghJvJGD9q6Hk"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf1_4Qucol8r"
      },
      "source": [
        "!mkdir \"/content/celebA\"\n",
        "!sudo unzip \"/content/drive/MyDrive/img_align_celeba.zip\" -d \"/content/celebA\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxwqQy0Hqt2j"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets import CIFAR10\n",
        "from PIL import Image\n",
        "from torch.utils.data import Subset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFH3oOMwsjLw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a69f7f30-3b1c-4abd-efc9-4dd62ea5f162"
      },
      "source": [
        "lr = 0.001\n",
        "batch_size = 16\n",
        "beta1 = 0\n",
        "beta2 = 0.99\n",
        "criterion = nn.BCELoss()\n",
        "c_lambda = 10\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEf2xiKlqrMM"
      },
      "source": [
        "# class CelebA(Dataset):\n",
        "  \n",
        "#   def __init__(self, root, transform=None):\n",
        "#     self.files = glob.glob(os.path.join(root, \"*.jpg\"))\n",
        "#     self.transform = transform\n",
        "\n",
        "#   def __getitem__(self, index):\n",
        "\n",
        "#     image = Image.open(self.files[index]) \n",
        "\n",
        "#     if self.transform is not None:\n",
        "#       return self.transform(image)\n",
        "    \n",
        "#     return image\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.files)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_7j4kVq5q1"
      },
      "source": [
        "def loaderFunc(transform):\n",
        "  \n",
        "  # ds = CIFAR10('~/.torch/data/', train=True, download=True, transform=transform)\n",
        "  # dog_indices, deer_indices, other_indices = [], [], []\n",
        "  # dog_idx, deer_idx = ds.class_to_idx['dog'], ds.class_to_idx['airplane']\n",
        "\n",
        "  # for i in range(len(ds)):\n",
        "  #   current_class = ds[i][1]\n",
        "  #   if current_class == dog_idx:\n",
        "  #     dog_indices.append(i)\n",
        "  #   elif current_class == deer_idx:\n",
        "  #     deer_indices.append(i)\n",
        "  #   else:\n",
        "  #     other_indices.append(i)\n",
        "  # dog_indices = dog_indices[:int(0.6 * len(dog_indices))]\n",
        "  # deer_indices = deer_indices[:int(0.6 * len(deer_indices))]\n",
        "  # new_dataset = Subset(ds, deer_indices)\n",
        "  \n",
        "  # dataset = CelebA(\"/content/drive/MyDrive/haircolors/images/img_align_celeba/\", transform=transform)\n",
        "  # dataset = CIFAR10('~/.torch/data/', train=True, download=True, transform=transform)\n",
        "  dataset = ImageFolder(\"/content/celebA\", transform=transform)\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "  )\n",
        "\n",
        "  return train_loader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-m8sSRosqnT"
      },
      "source": [
        "def sample_data(image_size=4):\n",
        "\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.CenterCrop(image_size),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])\n",
        "\n",
        "\n",
        "  loader = loaderFunc(transform)\n",
        "\n",
        "  for img, label in loader:\n",
        "      yield (img, label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNeFwJd7p-iM"
      },
      "source": [
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/06/Tables-Showing-Generator-and-Discriminator-Configuration-for-the-Progressive-Growing-GAN.png\"  width=\"1024\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHNR63_s1wha"
      },
      "source": [
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        # assuming input is in the from of (batch_size, channels, width, height)\n",
        "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True)\n",
        "                                  + 1e-8)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJEXRMkNgpNg"
      },
      "source": [
        "# class EqualLR:\n",
        "#     def __init__(self, name):\n",
        "#         self.name = name\n",
        "\n",
        "#     def compute_weight(self, module):\n",
        "#         weight = getattr(module, self.name + '_orig')\n",
        "#         fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
        "\n",
        "#         return weight * sqrt(2 / fan_in)\n",
        "\n",
        "#     @staticmethod\n",
        "#     def apply(module, name):\n",
        "#         fn = EqualLR(name)\n",
        "\n",
        "#         weight = getattr(module, name)\n",
        "#         del module._parameters[name]\n",
        "#         module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
        "#         module.register_forward_pre_hook(fn)\n",
        "\n",
        "#         return fn\n",
        "\n",
        "#     def __call__(self, module, input):\n",
        "#         weight = self.compute_weight(module)\n",
        "#         setattr(module, self.name, weight)\n",
        "\n",
        "\n",
        "# def equal_lr(module, name='weight'):\n",
        "#     EqualLR.apply(module, name)\n",
        "\n",
        "#     return module"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afJX5Mt3151W"
      },
      "source": [
        "from math import sqrt \n",
        "def EqualLR(module, input):\n",
        "  \n",
        "  weight = getattr(module, \"weight_orig\")\n",
        "  setattr(module, \"weight\", weight * sqrt(2 / (weight.size(1) * weight[0][0].numel())))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZnmcI-r18yZ"
      },
      "source": [
        "class EqualConv2d(nn.Module):\n",
        "  \n",
        "  def __init__(self, *args, **kwargs):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    conv = nn.Conv2d(*args, **kwargs)\n",
        "    conv.weight.data.normal_()\n",
        "    conv.bias.data.zero_()\n",
        "    \n",
        "    \n",
        "    weight = getattr(conv, 'weight')\n",
        "    del conv._parameters['weight']\n",
        "    conv.register_parameter(\"weight_orig\", nn.Parameter(weight.data))\n",
        "    conv.register_forward_pre_hook(EqualLR)\n",
        "    \n",
        "    # conv.register_forward_pre_hook(EqualLR)\n",
        "    # self.conv = equal_lr(conv)\n",
        "    self.conv = conv\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRBQPRbOo6Zw"
      },
      "source": [
        "def GeneratorBlock(in_channel, out_channel, output_size, first_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if first_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=4, padding=3),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      nn.Upsample((output_size, output_size), mode='bilinear', align_corners=True),\n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      PixelNorm(),\n",
        "    )\n",
        "\n",
        "  return model  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJAXqq9RnRK"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block4_4 = GeneratorBlock(512, 512, 4, first_block=True)\n",
        "    self.block8_8 = GeneratorBlock(512, 512, 8)\n",
        "    self.block16_16 = GeneratorBlock(512, 512, 16)\n",
        "    self.block32_32 = GeneratorBlock(512, 512, 32)\n",
        "    self.block64_64 = GeneratorBlock(512, 256, 64)\n",
        "    self.block128_128 = GeneratorBlock(256, 128, 128)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "        self.block4_4,\n",
        "        self.block8_8,\n",
        "        self.block16_16,\n",
        "        self.block32_32,\n",
        "        self.block64_64,\n",
        "        self.block128_128\n",
        "    ])\n",
        "\n",
        "    self.to_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(256, 3, 1),\n",
        "      nn.Conv2d(128, 3, 1),\n",
        "    ])\n",
        "\n",
        "\n",
        "  def forward(self, x, step, alpha):\n",
        "    # we have six steps toward progressively increasing the output size\n",
        "    # alpha is the weight of output of new block compared to upsampled input\n",
        "    if step == 1: # no need to average\n",
        "      out = self.blocks[0](x)\n",
        "      out = self.to_rgbs[0](out)\n",
        "\n",
        "    elif step > 1:\n",
        "\n",
        "      for block in self.blocks[:step - 1]: # assuming all previous blocks have been trained completely\n",
        "        x = block(x)\n",
        "\n",
        "      # x_small_block = self.blocks[step-2](x) # 256 * 64 * 64\n",
        "      # x is 16 * 512 * 16 * 16\n",
        "      x_large_block = self.blocks[step-1](x) # 128 * 128 * 128\n",
        "      x_large_image = self.to_rgbs[step-1](x_large_block) # 3 * 128 * 128\n",
        "\n",
        "\n",
        "      x_small_upsample = F.interpolate(x, x_large_image.shape[-2:]) # 3 * 64 * 64\n",
        "      x_upsample_rgb = self.to_rgbs[step-2](x_small_upsample)\n",
        "\n",
        "      out = (alpha *  x_large_image) + (1 - alpha) * (x_upsample_rgb)\n",
        "\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDH-JnZYHPm"
      },
      "source": [
        "gen = Generator().to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn84hHtRY5fn",
        "outputId": "df3eff40-998d-4b85-ab8e-1df7f2b873d5"
      },
      "source": [
        "gen(torch.randn(16, 512, 1, 1).to(device), 5, 0.2).shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g3DKw5_z8Kz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW1j9BBz-WC1"
      },
      "source": [
        "def DiscriminatorBlock(in_channel, out_channel, output_size, last_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if last_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=4, padding=0),\n",
        "      nn.LeakyReLU(0.2),\n",
        "      nn.Flatten(start_dim=1),\n",
        "      nn.Linear(512, 1),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      EqualConv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      EqualConv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      PixelNorm(),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.AvgPool2d(kernel_size=2),\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4KnipaT-GVK"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block64_64 = DiscriminatorBlock(128, 256, 64)\n",
        "    self.block32_32 = DiscriminatorBlock(256, 512, 32)\n",
        "    self.blcok16_16 = DiscriminatorBlock(512, 512, 16)\n",
        "    self.block8_8 = DiscriminatorBlock(512, 512, 8)\n",
        "    self.block4_4 = DiscriminatorBlock(512, 512, 4)\n",
        "    self.block1_1 = DiscriminatorBlock(513, 512, 1, last_block=True)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "      self.block64_64,\n",
        "      self.block32_32,\n",
        "      self.blcok16_16,\n",
        "      self.block8_8,\n",
        "      self.block4_4,\n",
        "      self.block1_1\n",
        "    ])\n",
        "\n",
        "    self.from_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(3, 128, 1),\n",
        "      nn.Conv2d(3, 256, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "      nn.Conv2d(3, 512, 1),\n",
        "    ])\n",
        "  \n",
        "\n",
        "  def forward(self, x_large, step, alpha):\n",
        "      \n",
        "    # alpha\n",
        "    \n",
        "\n",
        "    if step == 1:\n",
        "      x_large = self.from_rgbs[(6-step)](x_large) # input : 3 * 8 * 8 and output is 512 * 8 * 8\n",
        "      minibatch_std = x_large.std(0).mean() # 1\n",
        "      minibatch_std = minibatch_std.expand(x_large.size(0), 1, 4, 4) # 16, 1, 4, 4\n",
        "      x_large = torch.cat([x_large, minibatch_std], dim=1)\n",
        "      out = self.blocks[-step](x_large) # last layer output is 512 * 4 * 4\n",
        "      return out\n",
        "\n",
        "    out = self.blocks[-step](self.from_rgbs[6 - step](x_large)) # last layer output is 512 * 4 * 4\n",
        "    \n",
        "    if step > 1:\n",
        "    \n",
        "      x_large_downsampled = self.from_rgbs[(6 - step) + 1](F.avg_pool2d(x_large, kernel_size=2)) # input 3 * 8 * 8 => 3 * 4 *4  and then from rgb to 512 * 4 *4 \n",
        "\n",
        "      out = (1 - alpha) * x_large_downsampled + (alpha * out)\n",
        "\n",
        "\n",
        "      # intermidiate lay\n",
        "      for block in self.blocks[(6 - step) + 1: -1]:\n",
        "        out = block(out)\n",
        "\n",
        "      # last layer needs mini-batch variation\n",
        "      minibatch_std = x_large.std(0).mean() # 1\n",
        "      minibatch_std = minibatch_std.expand(x_large.size(0), 1, 4, 4) # 16, 1, 4, 4\n",
        "      out = torch.cat([out, minibatch_std], dim=1)\n",
        "      out = self.blocks[5](out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJTv8pBFwD0s"
      },
      "source": [
        "disc = Discriminator().to(device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWZCNeOVaxfU",
        "outputId": "f5d1e70a-a45a-4676-bdcb-89d2e5bceae9"
      },
      "source": [
        "disc(torch.randn(16, 3, 64, 64).to(device), 5, 0.2).shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9tReO2otNA"
      },
      "source": [
        "gen_optim = torch.optim.Adam(gen.parameters(), lr=lr , betas=(beta1, beta2))\n",
        "disc_optim = torch.optim.Adam(disc.parameters(), lr=lr , betas=(beta1, beta2))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY1lvWfrM2V4"
      },
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX1j3P4pSHsZ"
      },
      "source": [
        "def gradient_penalty(real, fake, epsilon, step, alpha):\n",
        "  \n",
        "  mixed_images = epsilon * real + (1 - epsilon) * fake\n",
        "  mixed_scores = disc(mixed_images, step, alpha)\n",
        "\n",
        "  gradients = torch.autograd.grad(\n",
        "      outputs=mixed_scores,\n",
        "      inputs=mixed_images,\n",
        "      grad_outputs=torch.ones_like(mixed_scores),\n",
        "      retain_graph=True,\n",
        "      create_graph=True,\n",
        "  )[0]\n",
        "\n",
        "  flat_gradients = gradients.reshape(len(gradients), -1)\n",
        "\n",
        "  norm = torch.norm(flat_gradients, dim=1)\n",
        "\n",
        "  gp = torch.mean((norm - 1) ** 2)\n",
        "\n",
        "  return gp"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J72ClzMoh-hT"
      },
      "source": [
        "# step and alpha\n",
        "step = 1\n",
        "step_size = 0.00002\n",
        "alpha = 0\n",
        "latent_space_size = 512\n",
        "i = 0\n",
        "stabilize = False"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPNvY34mibqZ"
      },
      "source": [
        "ckpt = torch.load(\"/content/drive/MyDrive/progressive_gan_checkpoints/ckpt_iteration_5000\")\n",
        "disc.load_state_dict(ckpt[\"disc_model\"])\n",
        "gen.load_state_dict(ckpt[\"gen_model\"])\n",
        "disc_optim.load_state_dict(ckpt[\"disc_optim\"])\n",
        "gen_optim.load_state_dict(ckpt[\"gen_optim\"])\n",
        "iteration = ckpt[\"iteration\"] \n",
        "alpha = ckpt[\"alpha\"]\n",
        "step = ckpt[\"step\"]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdi1A2CGjab8"
      },
      "source": [
        "def accumulate(model1, model2, weight=0.999):\n",
        "  \n",
        "  model1_params = dict(model1.named_parameters())\n",
        "  model2_params = dict(model2.named_parameters())\n",
        "\n",
        "  for key in model1_params.keys():\n",
        "    model1_params[key].data.mul_(weight).data.add_((1 - weight) * model2_params[key].data)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrhsMuKIjsrE"
      },
      "source": [
        "### Unit Test \n",
        "\n",
        "# gen1 = Generator()\n",
        "# gen2 = Generator()\n",
        "# accumulate(gen1, gen2, 0.5)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLMP6_vEl1XS"
      },
      "source": [
        "g_running = Generator().to(device)\n",
        "g_running.train(False)\n",
        "accumulate(g_running, gen, 0)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK7ZessInM-X"
      },
      "source": [
        "import numpy as np\n",
        "disc_loss_list = []\n",
        "gen_loss_list = []"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "keUlI2GTn7m-",
        "outputId": "791cb501-3d04-4224-8cfd-429701542ca0"
      },
      "source": [
        "# pbar = tqdm(range(iteration, 600000))\n",
        "from tqdm import trange\n",
        "pbar = trange(iteration, 600000, initial=iteration)\n",
        "dataset = sample_data(2 ** (step + 1))\n",
        "\n",
        "for iteration in pbar:\n",
        "\n",
        "  alpha = min(1, i * step_size)\n",
        "\n",
        "  if stabilize == False and i > 50000:\n",
        "    stabilize = True\n",
        "    alpha = 1\n",
        "    dataset = sample_data(2 ** (step + 1))\n",
        "  \n",
        "  if i > 100000:\n",
        "    alpha = 0\n",
        "    step += 1\n",
        "    stabilize = False\n",
        "    i = 0\n",
        "    \n",
        "    if step > 6:\n",
        "      step = 6\n",
        "      alpha = 0\n",
        "\n",
        "    dataset = sample_data(2 ** (step + 1))\n",
        "  i += 1\n",
        "\n",
        "  try:\n",
        "    real, _ = next(dataset)\n",
        "  except(OSError, StopIteration):\n",
        "    dataset = sample_data(2 ** (step + 1))\n",
        "    real, _ = next(dataset)\n",
        "\n",
        "  real = real.to(device)\n",
        "\n",
        "  # Training Discriminator\n",
        "  disc_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(len(real), latent_space_size, 1, 1).to(device), step, alpha).detach()\n",
        "  pred_fake = disc(fake, step, alpha)\n",
        "\n",
        "  pred_real = disc(real, step, alpha)\n",
        "\n",
        "  epsilon = torch.randn(len(real), 1, 1, 1, requires_grad=True).to(device)\n",
        "\n",
        "  gp = gradient_penalty(real, fake, epsilon, step, alpha)\n",
        "\n",
        "  disc_loss = - torch.mean(pred_real - pred_fake) + (c_lambda * gp)\n",
        "\n",
        "  disc_loss.backward()\n",
        "\n",
        "  disc_optim.step()\n",
        "\n",
        "  # Training Generator\n",
        "  gen_optim.zero_grad()\n",
        "\n",
        "  fake = gen(torch.randn(batch_size, latent_space_size, 1, 1).to(device), step, alpha)\n",
        "  pred_fake = disc(fake, step, alpha).reshape(-1)\n",
        "  gen_loss = - torch.mean(pred_fake)\n",
        "\n",
        "  gen_loss.backward()\n",
        "\n",
        "  gen_optim.step()\n",
        "\n",
        "  accumulate(g_running, gen)\n",
        "\n",
        "\n",
        "  disc_loss_list.append(disc_loss.item())\n",
        "  gen_loss_list.append(gen_loss.item())\n",
        "\n",
        "  pbar.set_description(\n",
        "    \"Generator loss : {:.5f}, Discriminator loss: {:.5f}, alpha is {:.5f} and step is {}\".format(gen_loss.item(), disc_loss.item(), alpha, step)\n",
        "  )\n",
        "\n",
        "  if iteration % 1000 == 0:\n",
        "    \n",
        "    fake_samples = g_running(\n",
        "        torch.randn(16, latent_space_size, 1, 1).to(device),\n",
        "        step, \n",
        "        alpha,\n",
        "    )\n",
        "    # visualize(fake_samples, \"linear_{}\".format(iteration))\n",
        "    visualize((torch.tanh(fake_samples) + 1) / 2, \"tanh_{}\".format(iteration), path=\"/content/drive/MyDrive/progressive_gan_checkpoints/samples\", save=True)\n",
        "    visualize(real, \"Real\")\n",
        "    \n",
        "  \n",
        "  if iteration % 10000 == 0:\n",
        "    torch.save({\n",
        "        \"gen_model\": gen.state_dict(),\n",
        "        \"gen_optim\": gen_optim.state_dict(),\n",
        "        \"disc_model\": disc.state_dict(),\n",
        "        \"disc_optim\": disc_optim.state_dict(),\n",
        "        \"iteration\": iteration,\n",
        "        \"step\": step,\n",
        "        \"alpha\": alpha,\n",
        "    }, \"/content/drive/MyDrive/progressive_gan_checkpoints/ckpt_iteration_{}\".format(iteration))\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generator loss : -3.24193, Discriminator loss: 0.27427, alpha is 0.22500 and step is 1:   3%|▎         | 16000/584447 [00:56<19:22:01,  8.15it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generator loss : -2.20794, Discriminator loss: -0.03902, alpha is 0.23658 and step is 1:   3%|▎         | 16580/584447 [02:08<19:32:48,  8.07it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bg1zE1-2iIs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}