{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik6KFYkEo23e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNeFwJd7p-iM"
      },
      "source": [
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/06/Tables-Showing-Generator-and-Discriminator-Configuration-for-the-Progressive-Growing-GAN.png\"  width=\"1024\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJAXqq9RnRK"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.block4_4 = GeneratorBlock(512, 512, 8, first_block=True)\n",
        "    self.block8_8 = GeneratorBlock(512, 512, 8)\n",
        "    self.block16_16 = GeneratorBlock(512, 512, 16)\n",
        "    self.block32_32 = GeneratorBlock(512, 512, 32)\n",
        "    self.block64_64 = GeneratorBlock(512, 256, 64)\n",
        "    self.block128_128 = GeneratorBlock(256, 128, 128)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "        self.block4_4,\n",
        "        self.block8_8,\n",
        "        self.block16_16,\n",
        "        self.block32_32,\n",
        "        self.block64_64,\n",
        "        self.block128_128\n",
        "    ])\n",
        "\n",
        "    self.to_rgbs = nn.ModuleList([\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(512, 3, 1),\n",
        "      nn.Conv2d(256, 3, 1),\n",
        "      nn.Conv2d(128, 3, 1),\n",
        "    ])\n",
        "\n",
        "\n",
        "  def forward(self, x, step, alpha):\n",
        "    # we have six steps toward progressively increase the output\n",
        "    # alpha is the weight of output of new block compared to upsampled input\n",
        "    if step == 1: # no need to average\n",
        "      out = self.blocks[0](x)\n",
        "\n",
        "    elif step > 1:\n",
        "\n",
        "      for block in self.blocks[:step - 2]: # assuming all previous blocks have been trained completely\n",
        "        x = block(x)\n",
        "\n",
        "      x_small_block = self.blocks[step-2](x) # 512 * 32 * 32\n",
        "      x_small_image = self.to_rgbs[step-2](x_small_block) # 3 * 32 * 32\n",
        "\n",
        "      x_large_block = self.blocks[step-1](x_small_block) # 256 * 64 * 64\n",
        "      x_large_image = self.to_rgbs[step-1](x_large_block) # 3 * 64 * 64\n",
        "\n",
        "\n",
        "      x_small_upsample = F.interpolate(x_small_image, x_large_image.shape[-2:]) # 3 * 64 * 64\n",
        "\n",
        "      out = (alpha *  x_large_image) + (1 - alpha) * (x_small_upsample)\n",
        "\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDH-JnZYHPm"
      },
      "source": [
        "gen = Generator()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn84hHtRY5fn",
        "outputId": "e887e4b7-53dd-45a8-c57b-fb814203de8d"
      },
      "source": [
        "gen(torch.randn(16, 512, 1, 1), 6, 0.2).shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 128, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRBQPRbOo6Zw"
      },
      "source": [
        "def GeneratorBlock(in_channel, out_channel, output_size, first_block=False):\n",
        "  # Growing gradually to 1024 * 1024 is done by incrementally adding blocks\n",
        "  # in this function we get specification of the block and return it\n",
        "  # for example input would be 4 * 4 and output_size would be 8 * 8\n",
        "  if first_block:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=4, padding=3),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "    )\n",
        "  else:\n",
        "\n",
        "    model = nn.Sequential(\n",
        "    \n",
        "      nn.Upsample((output_size, output_size), mode='bilinear', align_corners=True),\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
        "      nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g3DKw5_z8Kz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkDDcbc2z8QN",
        "outputId": "9e4b5606-6f25-4620-f41b-cedf83454e43"
      },
      "source": [
        "!git clone \"https://github.com/rosinality/progressive-gan-pytorch.git\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'progressive-gan-pytorch'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Total 22 (delta 0), reused 0 (delta 0), pack-reused 22\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_vINmVzz9nV",
        "outputId": "a5ba22f5-7d62-4a9c-887a-4444e2f62b7f"
      },
      "source": [
        "%cd /content/progressive-gan-pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/progressive-gan-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKXLFPnR0B3Z"
      },
      "source": [
        "from model import Generator, Discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmH5QRUr0GH7"
      },
      "source": [
        "n_label = 1\n",
        "code_size = 512 - n_label\n",
        "generator = Generator(code_size, n_label)\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H7P1GB50O03",
        "outputId": "6927aa24-9873-4cf5-dbe6-ae9ed6b975ae"
      },
      "source": [
        "generator(torch.randn(batch_size, code_size), torch.zeros(batch_size).int()).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSpFYpNn40gR"
      },
      "source": [
        "from model import ConvBlock"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDnRvtzn41it"
      },
      "source": [
        "cb = ConvBlock(512, 512, 4, 3, 3, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lt_zdCQ5k74",
        "outputId": "f789c250-6e9f-40c7-ac5f-bf05cf45dacf"
      },
      "source": [
        "cb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvBlock(\n",
              "  (conv): Sequential(\n",
              "    (0): EqualConv2d(\n",
              "      (conv): Conv2d(512, 512, kernel_size=(4, 4), stride=(1, 1), padding=(3, 3))\n",
              "    )\n",
              "    (1): PixelNorm()\n",
              "    (2): LeakyReLU(negative_slope=0.2)\n",
              "    (3): EqualConv2d(\n",
              "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (4): PixelNorm()\n",
              "    (5): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKvSPSlw5Yzr",
        "outputId": "0ddaff46-8d6a-44d1-856e-c6d79b9c9b5e"
      },
      "source": [
        "cb.conv[0](torch.randn(16, 512, 1, 1)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WYcMXPo5L6R",
        "outputId": "cd15e89a-751e-4318-a46a-3e9c52a9af16"
      },
      "source": [
        "cb(torch.randn(16, 512, 1, 1)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuIWE7w15U78"
      },
      "source": [
        "con2 = torch.nn.Conv2d(512, 512, kernel_size=(4, 4), stride=(1, 1), padding=(3, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNhXu9_-5vLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dbccf05-4cce-4280-ed21-db268a9c80a8"
      },
      "source": [
        "con2(torch.randn(16, 512, 1, 1)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34umbZc_5zJY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}